<section class="colored-section">
    <div class="col-lg-12">
     <h1 class="sub-section-header" id="server-administration-basics">
      <mark>
       Server Administration Basics
      </mark>
     </h1>
    </div>
    <div class="sub-section-box col-lg-12">
     <h3 id="out-of-band-management">
      Out of Band Management
     </h3>
     <ul class="spaced-list ">
      <li>
       In an enterprise or datacenter environment, being able to maintain and operate servers remotely is very important. As such, there are several common tools that can be used to control remote servers.
      </li>
      <ul >
       <li>
        iLO (Integrated Lights-Out): This is a proprietary technology from Hewlett-Packard Enterprise (HPE) that allows for remote management of servers. iLO is embedded or integrated in all HPE ProLiant servers. It allows administrators to manage servers remotely, perform configuration, update firmware, and monitor performance. These management tasks can be performed regardless of the state of the operating system or even if no operating system is installed. Administrators can access iLO through a web-based interface by connecting to the iLO IP address assigned during the configuration process. This interface provides access to a wide range of management tasks. Additionally, iLO can be accessed via a command-line interface for scripting and automation purposes. HPE also provides the iLO Mobile app, which allows server management from a smartphone or tablet.
       </li>
       <li>
        iDRAC (Integrated Dell Remote Access Controller): This is Dell's equivalent to iLO. This is a proprietary technology that is integrated into all Dell PowerEdge servers. Like iLO, iDRAC allows for remote management of servers, including configuration, firmware updates, performance monitoring, and more. Similar to iLO, iDRAC can be accessed through a web-based interface by connecting to the iDRAC IP address. It can also be accessed via command-line interface, and Dell provides the OpenManage Mobile app for managing servers from a mobile device. iDRAC is also integrated with Dell's OpenManage suite of systems management tools.
       </li>
       <li>
        WBEM (Web-Based Enterprise Management) represents a set of management and Internet standard technologies. They are developed to unify the management of enterprise computing environments. WBEM provides a well-defined method for systems, applications, networks, devices, and services to describe themselves, their functionality, their configuration, and their status.
       </li>
       <li>
        IP KVM (IP Keyboard, Video, Mouse) is a technology. It allows remote access to a computer or server over a network connection. It provides the same functionality as a local keyboard, video display, and mouse, allowing a remote user to perform any operation that could be done with direct physical access. IP KVM switches are often used in data centers to allow remote access to servers.  IP KVM devices typically have a web-based interface that allows administrators to view the screen of the remote server and interact with it as if they were physically present. Some IP KVM devices also have client software that provides additional features.
       </li>
       <li>
        IPMI (Intelligent Platform Management Interface) consists of computer interface specifications for an autonomous computer subsystem. It provides management and monitoring capabilities independently of the host system's CPU, firmware (BIOS or UEFI), and operating system. IPMI allows an administrator to manage multiple servers from a single location. This can include powering the system on and off, rebooting it, and alerting when there are issues.
       </li>
      </ul>
      <li>
       Local Hardware Administration (common tools when working with on-hand servers)
      </li>
      <ul >
       <li>
        KVM (Keyboad, Video, Mouse)
       </li>
       <li>
        "Crash Cart": Multimeter or other hardware diagnostic tools, replacement hardware components, anti-static strap.
       </li>
       <li>
        Serial connectivity
       </li>
       <li>
        Console connections
       </li>
      </ul>
     </ul>
     <h3 id="operating-system-installation">
      Operating System Installation
     </h3>
     <ul class="spaced-list ">
      <li>
       There are many situations where it may be necessary to install or re-install the operating system on a device. For example, a new device with blank drives, or an existing system that needs to have a different OS for whatever reason.
      </li>
      <li>
       To install the operating system, there are some common tools that you will need. The main tool is "installation media". Installation media is generally a USB flash drive or a CD with the software required to install the operating system loaded on to it. In an enterprise setting, the installation media may also be a place on the network.
      </li>
      <li>
       For windows systems, you can purchase installation media through many retailers, or it may be provided to you by the manufacturer of your device. I have links to the windows media creation tools for windows 10 &amp; 11
       <a class="link" href="/tools#links" target="_blank">
        here
       </a>
       if you want to create your own. After installing windows, you can use
       <a class="link" href="https://github.com/massgravel/Microsoft-Activation-Scripts" target="_blank">
         Microsoft Activation Scripts
        </a>
        to activate your copy of windows, or purchase a key online.
      </li>
      <li>
       For unix or linux systems, you may need to use a tool like Rufus to create your own installation media. Generally the only other thing needed is an ISO file for the operating system you want to install.
      </li>
      <li>
       In an enterprise environment, it is more common to use a system image rather than an a blank version of an operating system on the installation media. A system image will include all the required software, security, and settings preconfigured so that it does not need to be re-done every time the operating system needs to be installed.
      </li>
      <li>
       An alternative to an image is a clone. Cloning a drive means copying all of its contents, including partitions and its Master Boot Record identically to another disk. This means that if a disk with an operating system installed on it gets cloned, it will be possible to boot to the new drive, with all of the applications and data in tact from the old drive. However
       <mark>
        cloning is natorious for failing or causing data corruption unless you are cloning to an identical drive
       </mark>
      </li>
      <li>
       when you install an operating system, it can be installed either on hardware (referred to as a bare metal install) or on a virtual machine.
      </li>
      <li>
       Before installing an operating system, the installation media will generally prompt to initialize and format the disk to support the file system for that operating system. Once the installtion process begins, the installation media will create the required partitions for the OS.
      </li>
      <li>
       When partitioning a drive, there are different methods of organizing the partiton tables on a hard drive or ssd. Typically, this will be decided by the operating system you are installing.
      </li>
      <ul >
       <li>
        MBR (Master Boot Record): MBR is an older method that's used by BIOS-based systems. The MBR itself is a 512-byte sector at the beginning of the drive that contains a bootloader and the partition table. MBR has some limitations due to its age:
       </li>
       <ul >
        <li>
         It can only handle drives up to 2 TB in size.
        </li>
        <li>
         It can only handle up to four primary partitions. If you want more, you have to make one of them an "extended partition" and create "logical partitions" within it.
        </li>
        <li>
         It doesn't have any built-in error checking to protect the data in the partition table.
        </li>
       </ul>
       <li>
        GPT (GUID Partition Table): GPT is a newer method that's used by UEFI-based systems. GPT doesn't have the limitations that MBR does:
       </li>
       <ul >
        <li>
         In terms of disk size, GPT uses 64 bits for logical block addresses, allowing for a maximum disk size of 2^64 sectors. Given that the industry standard sector size is 512 bytes, this allows for a maximum disk size of 9.4 Zettabytes (1 Zettabyte = 1 billion Terabytes). However, some systems and disks use larger sector sizes, such as 4096 bytes, which would allow for even larger maximum disk sizes.
        </li>
        <li>
         It can handle up to 128 primary partitions by default in Windows (and more in other operating systems).
        </li>
        <li>
         It stores multiple copies of the partition table across the disk and includes cyclic redundancy check (CRC) values to check that its data is intact, so it's more robust and can recover from data corruption better than MBR can.
        </li>
       </ul>
       <li>
        Dynamic Disks: This is a feature of Microsoft Windows that allows for more flexible management of disk space. Unlike basic disks, which are limited to four primary partitions, dynamic disks can contain a large number of dynamic volumes (the equivalent of partitions). These volumes can be resized without having to restart Windows. Dynamic disks also support features that aren't available with basic disks, such as the ability to create spanned, striped (RAID-0), mirrored (RAID-1), and RAID-5 volumes for improved performance and data protection.
       </li>
       <li>
        LVM (Logical Volume Management): LVM is a feature of Linux that provides a more flexible way of managing disk space. Instead of being divided into partitions, a disk is divided into physical volumes (PVs). These PVs can be combined into volume groups (VGs), and logical volumes (LVs) can be created from the space in a VG. This allows for easy resizing of disk space and the ability to span a filesystem across multiple disks. LVM also supports snapshots, which are a point-in-time copy of a logical volume, and can be used for backups or testing.
       </li>
      </ul>
     </ul>
     <h3 id="basic-networking-ip-configuration">
      Basic Networking: IP (Internet Protocol) Configuration
     </h3>
     <ul class="spaced-list">
      <h4>
       IPV4
      </h4>
      <ul class="spaced-list">
       <li>
        IPV4 addresses are 32 bits long, Expressed in 4, 8 bit groups (called octets) seperated by a period. ex:
        <code>
         192.168.1.1
        </code>
       </li>
       <li>
        Data is transmitted in packets, each with its own IP header containing source and destination IP addresses, among other information.
       </li>
       <li>
        Due to the length of IPV4 addresses, there are not enough addresses to support the number of devices that are being connected. Because of this, devices generally are not assigned their own public IPV4 adress, and are instead assigned a private IP apdress, and then the devices router will use NAT (Network Adress Translation) to ensure data from outside of the LAN (Local Area Network) goes to and from the correct device.
       </li>
      </ul>
      <h4>
       Sub Net Mask
      </h4>
      <ul class=" spaced-list">
       <li>
        "The subnet mask determines the network on which the host resides". Basically, it is an indicator of how many bits in an IP adress are used to specify the network the device resides on.
       </li>
       <li>
        Subnet mask can be indicated by two notations. Both notations serve the same purpose but are used in different contexts. Dotted decimal notation is often used in network configurations, while CIDR notation is commonly used in routing and when specifying IP address ranges.
       </li>
       <ol>
        <li>
         Dotted Decimal Notation: This is the traditional way of representing a subnet mask. It consists of four octets (just like an IP address) and is expressed in decimal format. For example:
         <code>
          255.255.255.0
         </code>
        </li>
        <li>
         CIDR (Classless Inter-Domain Routing) Notation: This is a more concise way of representing a subnet mask. It uses a forward slash (/) followed by a number, which indicates the number of consecutive '1' bits in the subnet mask's binary form.
         <mark>
          For example:
         </mark>
         <code>
          /24
         </code>
         would be
         <code>
          11111111.11111111.11111111.00000000
         </code>
         (24 of the 32 bits are 1s) in binary, or
         <code>
          255.255.255.0
         </code>
         when converted to decimal notation.
        </li>
       </ol>
       <ul >
        <li>
         A subnet mask of 255.255.255.0 in dotted decimal notation is equivalent to /24 in CIDR notation. This is because the first 24 bits (three octets) are set to '1', and the remaining bits are '0'.
        </li>
        <li>
         It was easier for me to this about this as 24bit subnet divided by 8 bits = 3 octets would be required to display the same subnet mask.
        </li>
        <li>
         For many applications it can be helpful to 'subnet' a network, or split into many parts. Network Chuck has a great
         <a class="link" href="https://www.youtube.com/playlist?list=PLIhvC56v63IKrRHh3gvZZBAGvsvOhwrRF" target="_blank">
          playlist on Subnetting</a>. Powercert also has a <a class="link" href="https://www.youtube.com/watch?v=s_Ntt6eTn94" target="_blank">20 minute video</a> on the topic.
         </a>
        </li>
        <li id="#subnetting">
         Here are some of the
         <mark>
          benefits of subnetting:
         </mark>
        </li>
        <ul >
         <li>
          By breaking a large network into smaller subnets, local traffic remains local. This means that not all traffic is broadcasted to all parts of the network, reducing unnecessary traffic and congestion.
         </li>
         <li>
          Fewer devices per subnet can lead to faster performance and reduced latency.
         </li>
         <li>
          Different departments or groups can be isolated into different subnets. If one subnet is compromised, it doesn't necessarily mean that attackers have access to other subnets.
         </li>
         <li>
          Network policies, access controls, and firewall rules can be applied at the subnet level, allowing for more granular control over network resources.
         </li>
         <li>
          Subnetting can reflect the organizational structure or the physical layout of a company. For instance, different departments or floors in a building can have their own subnets.
         </li>
         <li>
          With fewer hosts in each subnet, identifying and resolving network issues can be more straightforward.
         </li>
         <li>
          Subnetting allows for the efficient allocation of IP addresses based on the actual number of hosts needed in each subnet, minimizing wasted IP addresses.
         </li>
         <li>
          As an organization grows, new subnets can be created without the need to redesign the entire network.
         </li>
         <li>
          Routers can summarize routes to multiple subnets as a single routing table entry, reducing the size of routing tables and improving routing efficiency.
         </li>
         <li>
          With smaller routing tables, routers can make routing decisions more quickly.
         </li>
         <li>
          When connecting to ISPs or other external networks, organizations often receive a limited block of IP addresses. Subnetting allows the organization to divide this block internally to meet their needs.
         </li>
         <li>
          If a particular department or segment of the network grows, it can be moved to a larger subnet without affecting the rest of the network.
         </li>
         <li>
          If two companies merge, their networks might overlap in IP address space. Subnetting can help reorganize and integrate the networks.
         </li>
         <li>
          I was confused on how subnets and vlans are different so
          <a class="link" href="/notes/other#subnetting-vs-vlans" target="_blank">
           here
          </a>
          is more information on the difference.
         </li>
        </ul>
        <li>
         If you need more granular control of the number of hosts on your network, you can use subnet masks that are not multiples of 8.
         <mark>
          For example:
         </mark>
         <code>
          /20
         </code>
         would be
         <code>
          11111111.11111111.11110000.00000000
         </code>
         in binary, or
         <code>
          255.255.240.0
         </code>
         in decimal notation. You can use this to leave more or less space for hosts (devices) on the network as needed.
        </li>
        <li>
         The IPV4 subnet mask can be assigned in a range from 1 to 32.
        </li>
        <li>
         A subnet mask of /32 specifies that all 32 bits of the IP address are dedicated to the network portion, leaving no bits for host addresses within that subnet.
        </li>
        <ul >
         <li>
          A /32 mask denotes a single, specific IPv4 address. For example, 192.168.1.10/32 refers precisely to the IP address 192.168.1.10 and no other addresses.
         </li>
         <li>
          Since all bits are used for the network portion, there are no bits left for hosts. This means there are no available addresses for devices within that subnet, as the "subnet" itself is just a single IP address.
         </li>
         <li>
          In routing tables, a /32 can be used to specify a specific route to a single IP address.
         </li>
         <li>
          Firewalls might use /32 to denote rules that apply to a specific IP address.
         </li>
         <li>
          While a /32 doesn't allow for additional hosts in the subnet, the specific /32 IP address itself can be assigned to a device.
         </li>
        </ul>
        <li>
         While you could technically assign a subnet mask of /1, thats just goofy and you probably shouldn't. You probably don't have 2 billion devices on your network, no matter how dedicated you are to pimping out your room with phillips hue lights.
        </li>
       </ul>
       <li>
        <mark>
         For Example:
        </mark>
       </li>
       <ul >
        <li>
         192.168.1.1/24 would indicate the first 3 sections of the ip address indicate the network the device resides on, and this devices address on that network is 1.
        </li>
        <li>
         192.168.1.100/16 would indicate the first 2 sections of the ip address indicate the network the device resides on, and this devices address on that network is 1.100
        </li>
       </ul>
      </ul>
      <h4>
       IPV6
      </h4>
      <ul class="spaced-list">
       <li>
        IPV6 uses 128 bit addresses. Because the pool of IPV6 addresses is so much larger, using NAT is not required, so devices can have their own public IPV6 adress.
       </li>
       <li>
        Rather than Subnet Mask, IPV6 uses a "Subnet Prefix Length", which is indicated in the same CIDR notation, and operates in the same way as an IPV4 subnet mask would.
       </li>
      </ul>
      <h4>
       VLAN (Virtual Local Area Network)
      </h4>
      <ul class="spaced-list">
       <li>
        VLAN's are a logical subdivision of a switch.
       </li>
       <li>
        VLANs can be used to segment a larger network into smaller, more manageable pieces. This can improve performance by reducing the size of the broadcast domain and limiting the extent of broadcasts.
       </li>
       <li>
        By segregating devices into different VLANs based on their function or department, sensitive data can be restricted to specific VLANs, reducing the risk of unauthorized access.
       </li>
       <li>
        VLANs can be used to group devices by department or function, regardless of their physical location in a building or campus. This can simplify network management and troubleshooting.
       </li>
       <li>
        VLANs allow for flexibility in how devices are grouped together, and they can be easily modified or expanded as organizational needs change.
       </li>
       <li>
        Communication between different VLANs requires a router or a layer 3 switch, which can introduce additional latency and complexity.
       </li>
       <li>
        ACL's (Access Control List) can be used to control the traffic between VLAN's.
       </li>
      </ul>
      <h4>
       DNS (Domain Name System)
      </h4>
      <ul class="spaced-list">
       <li>
        Converts FQDN's to IP addresses.
       </li>
       <li>
        DNS "Resolution" Process:
       </li>
       <ol >
        <li>
         Local Cache Check: The client device (e.g., your computer) first checks its local cache to see if it already knows the IP address for the domain. If found, the process ends here.
        </li>
        <li>
         Query Recursive DNS Server: If the IP address isn't in the local cache, the client queries a recursive DNS server (usually provided by your ISP). This server checks its cache. If found, it returns the IP to the client.
        </li>
        <li>
         Query Root DNS Server: If the recursive server doesn't have the IP cached, it queries a root DNS server. The root server doesn't know the IP for individual domains but directs the recursive server to the appropriate TLD server.
        </li>
        <li>
         Query TLD Server: The recursive server then queries the TLD server for the domain's TLD (e.g., .com). The TLD server directs the recursive server to the domain's authoritative name server.
        </li>
        <li>
         Query Authoritative Name Server: The recursive server queries the authoritative name server for the domain. The authoritative server returns the IP address for the domain to the recursive server.
        </li>
        <li>
         Return IP Address to Client: The recursive server caches the IP address (for the duration specified by the TTL) and returns it to the client. The client's browser can now request the website using the IP address.
        </li>
       </ol>
      </ul>
      <h4>
       Firewalls
      </h4>
      <ul class="spaced-list">
       <li>
        For server+, only layer 4 firewalls are covered.
       </li>
       <li>
        Layer 4 implies host (device) level. These firewalls would be software such as windows firewall, iptables, or UFW (un-complicated firewall).
       </li>
       <li>
        layer 4 firewalls can control traffic up to layer 4, including:
       </li>
       <ul >
        <li>
         Source IP adress
        </li>
        <li>
         Destination IP adress
        </li>
        <li>
         source port
        </li>
        <li>
         destination port
        </li>
        <li>
         protocol type
        </li>
       </ul>
      </ul>
      <h4>
       Static vs Dynamic IP Adressing
      </h4>
      <ul class="spaced-list">
       <li>
        DHCP (Dynamic Host Configuration Protocol)
       </li>
       <ul class="spaced-list">
        <li>
         Dynamic Host Configuration Protocol (DHCP) is a network protocol used to automatically assign IP addresses and other related configuration information to devices on a network.
        </li>
        <li>
         DHCP servers dynamically assign IP addresses to devices on a network. Administrators can define and manage pools (ranges) of IP addresses to be assigned. This eliminates the need for network administrators to manually configure IP addresses for each device.
        </li>
        <li>
         DHCP servers assign IP addresses for a specific duration, known as a lease. Once the lease expires, the device must request a new IP address or renew its current one.
        </li>
        <li>
         DHCP servers centralize the management of IP addresses and related configurations, making it easier to manage and troubleshoot network issues.
        </li>
        <li>
         If needed, a server administrator can create a DHCP reservation. A DHCP reservation is a specific IP address that is reserved for a particular device, based on its MAC address.
        </li>
        <li>
         Other configuration information provided by DHCP may include the default gateway, DNS servers, and more.
        </li>
        <li>
         The DHCP process typically involves four steps, often referred to as DORA:
        </li>
        <ol >
         <li>
          Discover: The client sends a broadcast message searching for a DHCP server.
         </li>
         <li>
          Offer: The DHCP server responds with an offer that includes an available IP address.
         </li>
         <li>
          Request: The client requests the offered IP address.
         </li>
         <li>
          Acknowledge: The DHCP server acknowledges the request and assigns the IP address to the client.
         </li>
        </ol>
        <li>
         Common DHCP servers:
        </li>
        <ul >
         <li>
          Microsoft DHCP Server: Included with Windows Server operating systems.
         </li>
         <li>
          ISC DHCP: An open-source DHCP server commonly used in UNIX and Linux environments.
         </li>
         <li>
          Cisco IOS DHCP Server: Integrated into Cisco routers and switches.
         </li>
         <li>
          Kea: A modern open-source DHCP server developed by ISC as a successor to ISC DHCP.
         </li>
         <li>
          DHCP functionality in routers: Many home and enterprise routers have built-in DHCP servers.
         </li>
        </ul>
        <li>
         DHCP Security Considerations
        </li>
        <ul >
         <li>
          Rogue DHCP Servers: Unauthorized DHCP servers can provide incorrect configurations or act maliciously.
         </li>
         <li>
          DHCP Snooping: A security feature on switches that filters out untrusted DHCP messages.
         </li>
         <li>
          MAC Address Filtering: Some DHCP servers can be configured to only serve specific MAC addresses or exclude certain MAC addresses.
         </li>
        </ul>
       </ul>
       <li>
        APIPA (Automatic Private IP Adress)
       </li>
       <ul class="spaced-list">
        <li>
         Automatic Private IP Addressing (APIPA) is a feature primarily found in Microsoft Windows operating systems, though the concept exists in other systems under different names.
        </li>
        <li>
         APIPA acts as a safety net when a DHCP server is unavailable. Instead of leaving a device without an IP address, APIPA provides a temporary one.
        </li>
        <li>
         APIPA ensures that devices on the same network segment can communicate with each other even if there's no DHCP server available or if static IP addresses haven't been configured.
        </li>
        <li>
         APIPA assigns IP addresses from the range 169.254.0.1 to 169.254.255.254.
        </li>
        <li>
         The default subnet mask for APIPA is 255.255.0.0, meaning all APIPA addresses are on the same local subnet.
        </li>
        <li>
         Devices with APIPA addresses do not have a default gateway, restricting them to local communications only (they wont be able to access the internet, etc).
        </li>
        <li>
         APIPA is not meant to replace DHCP or static addressing. It's a temporary measure to allow basic network functionality.
        </li>
        <li>
         In environments where APIPA might pose a security risk, network administrators can segment networks or use VLANs to isolate traffic.
        </li>
        <li>
         How APIPA Works:
        </li>
        <ul >
         <li>
          When a device configured to obtain an IP address automatically starts up, it first tries to find a DHCP server.
         </li>
         <li>
          If the device can't find a DHCP server after several attempts, it assigns itself an IP address from the APIPA range.
         </li>
         <li>
          The device periodically checks for the presence of a DHCP server. If it finds one, it obtains an IP address from the server and stops using the APIPA address.
         </li>
        </ul>
       </ul>
       <li>
        Static IP Addressing:
       </li>
       <ul class="spaced-list">
        <li>
         Static IP addressing refers to the manual assignment of IP addresses to devices on a network, as opposed to dynamic assignment where IP addresses are automatically allocated by a service like DHCP (Dynamic Host Configuration Protocol).
        </li>
        <li>
         Once a device is assigned a static IP address, that address does not change unless it's manually reconfigured.
        </li>
        <li>
         Network administrators or users must manually set the IP address, subnet mask, default gateway, and other network parameters on the device.
        </li>
        <li>
         Servers, especially those accessible from the internet like web servers, often have static IP addresses to ensure consistent accessibility.
        </li>
        <li>
         Devices like routers, switches, and firewalls typically have static IP addresses for predictable management and configuration.
        </li>
        <li>
         In office environments, printers might be assigned static IP addresses so they can be consistently accessed by users.
        </li>
        <li>
         Devices that need to be accessed remotely, like security cameras or certain workstations, might use static IP addresses to ensure consistent access.
        </li>
        <li>
         Advantages of Static IP Addressing:
        </li>
        <ul >
         <li>
          Devices will always have the same IP address, making it easier to access and manage them.
         </li>
         <li>
          There's no need for a DHCP server, eliminating potential points of failure or misconfiguration.
         </li>
         <li>
          Since there's no need for DHCP discovery, offer, request, and acknowledgment processes, there's less network traffic related to IP address assignment.
         </li>
        </ul>
        <li>
         Disadvantages of Static IP Addressing:
        </li>
        <ul >
         <li>
          As the network grows, managing static IP addresses can become complex and time-consuming.
         </li>
         <li>
          If two devices are accidentally assigned the same IP address, it can lead to IP conflicts, causing network issues.
         </li>
         <li>
          Some IP addresses might remain unused if devices are not connected or if they're assigned inefficiently.
         </li>
        </ul>
        <li>
         Other considerations:
        </li>
        <ul >
         <li>
          It's crucial to maintain a record or documentation of all static IP assignments to prevent conflicts and aid in troubleshooting.
         </li>
         <li>
          Understanding subnetting is essential when manually assigning IP addresses to ensure devices can communicate efficiently and securely.
         </li>
         <li>
          Static IP addresses can be more predictable for potential attackers, so additional security measures might be needed for devices with static IPs, especially if they're accessible from the internet.
         </li>
        </ul>
       </ul>
      </ul>
      <h4>
       MAC (Media Access Control) Adress
      </h4>
      <ul >
       <li>
        The MAC address is a unique identifier assigned to network interfaces for communications at the Data Link layer (Layer 2) of the OSI model. They facilitate communication between devices within the same local network (LAN).
       </li>
       <li>
        Every network interface card (NIC) or network-capable device has a unique MAC address, ensuring distinct identification on a local network.
       </li>
       <li>
        A MAC address is typically represented as a sequence of 12 hexadecimal digits. It's often displayed in six groups of two hexadecimal digits, separated by colons (:) or hyphens. For example: AA-BB-CC-DD-EE-FF
       </li>
       <li>
        MAC adresses are split into 2 parts:
       </li>
       <ol >
        <li>
         Organizationally Unique Identifier (OUI): The first three bytes (AA-BB-CC in the example from before) represent the manufacturer of the NIC. This part is assigned by the IEEE.
        </li>
        <li>
         Universal Administered address (UAA): The last three bytes (DD-EE-FF in the example from before) are assigned by the manufacturer and ensure the card's uniqueness.
        </li>
       </ol>
       <li>
        MAC Address uses:
       </li>
       <ul >
        <li>
         Address Resolution Protocol (ARP) translates IP addresses into MAC addresses, allowing for correct packet delivery within a local network.
        </li>
        <li>
         Network administrators can set up MAC address filtering to allow or deny network access to specific devices.
        </li>
        <li>
         Since MAC addresses are unique, they can be used to track devices across different networks, though this can raise privacy concerns.
        </li>
       </ul>
       <li>
        There are 3 primary kinds of MAC addresses:
       </li>
       <ol >
        <li>
         Unicast Addresses
        </li>
        <ul >
         <li>
          A unicast MAC address is a unique identifier assigned to a single network interface card (NIC) or onboard network component. It ensures that the device has a distinct address on a local network.
         </li>
         <li>
          Unicast addresses are used for one-to-one communication between devices on a network. When a frame is sent to a unicast MAC address, only the specific device with that address processes the frame.
         </li>
         <li>
          Manufacturers assign unicast MAC addresses. The first half of the address (the Organizationally Unique Identifier or OUI) identifies the manufacturer, while the second half is a unique value assigned by the manufacturer to ensure the card's distinctiveness.
         </li>
         <li>
          While unicast MAC addresses are typically hardcoded into the device and remain constant, some software tools allow for MAC address spoofing or changing.
         </li>
        </ul>
        <li>
         Multicast MAC Addresses:
        </li>
        <ul >
         <li>
          A multicast MAC address represents a specific group of devices on a network. It doesn't point to a single device but rather a collection of devices that belong to a particular multicast group.
         </li>
         <li>
          Multicast addresses are used for one-to-many communication. When a frame is sent to a multicast MAC address, all devices that belong to the corresponding multicast group process the frame. It's more efficient than broadcasting a message to all devices, especially when only a subset of devices needs the information.
         </li>
         <li>
          A multicast MAC address can be identified by the value of its least significant bit of the first byte. If this bit is set to 1, it's a multicast address. For instance, a MAC address starting with 01 in hexadecimal is a multicast address.
         </li>
         <li>
          Multicast MAC addresses are commonly used in protocols like Internet Group Management Protocol (IGMP) for IP multicasting.
         </li>
        </ul>
        <li>
         Broadcast MAC Address:
        </li>
        <ul >
         <li>
          The broadcast MAC address is a special address that targets all devices on a local network segment.
         </li>
         <li>
          The broadcast MAC address is always FF:FF:FF:FF:FF:FF
         </li>
         <li>
          When a frame is sent to the broadcast MAC address, every device on the local network segment processes the frame. It's a one-to-all communication method.
         </li>
         <li>
          Examples:
         </li>
         <ul >
          <li>
           When a computer joins a network and needs an IP address, it doesn't know the address of the DHCP server (a service that assigns IP addresses). So, it sends a broadcast frame asking, "Is there a DHCP server out there?" The DHCP server, upon receiving this broadcast, will respond directly to the requesting computer.
          </li>
          <li>
           Another common use is the Address Resolution Protocol (ARP). If a device knows the IP address of another device but not its MAC address (which is needed for direct communication on a local network), it sends a broadcast frame asking, "Who has this IP address?" The device with that IP address will then reply with its MAC address.
          </li>
         </ul>
         <li>
          Excessive broadcasting can lead to "broadcast storms," which can congest the network. Modern network designs often use VLANs and other techniques to limit the scope of broadcasts.
         </li>
        </ul>
       </ol>
      </ul>
     </ul>
     <h3 id="server-roles">
      Server Roles
     </h3>
     <ul class="spaced-list">
      <li>
       Print Server
      </li>
      <ul >
       <li>
        handles print que. Print servers are generally depricated and no longer used do to "advances" in printing technology.
       </li>
      </ul>
      <li>
       Database server
      </li>
      <ul >
       <li>
        Stores data using applications such as an SQL or Oracle database.
       </li>
       <li>
        Data is generally accessed directly by applications, but can also be viewed by a database GUI, usually via a web portal.
       </li>
      </ul>
      <li>
       File Server
      </li>
      <ul >
       <li>
        File servers are used to store files for network users.
       </li>
       <li>
        In enterprise situations, users are required to store data on a file server rather than their personal device or client. This way, their data is always backed up, and accessible from other devices when needed.
       </li>
      </ul>
      <li>
       Web Server
      </li>
      <ul >
       <li>
        Hosts web pages for users accessing the server using  web browser.
       </li>
       <li>
        Web servers can be set up to only be available to devices on the local network. This can be helpful for internal buisness applications, or for testing a website before it is made public.
       </li>
       <li>
        Can be configured to require connections via https (Hyper Text Transfer Protocal Secure) isntead of http. https encrypts the data to and rom the client to prevent spoofing and man-in-the-middle attacks.
       </li>
      </ul>
      <li>
       Application Server
      </li>
      <ul >
       <li>
        Users can connect to these servers and have their application run on them rather than their client device. This is a great in networks that take advantage of "thin clients", where cheaper client devices are used for cost savings, and heavy workloads are completed on a more powerful remote server.
       </li>
      </ul>
      <li>
       Messaging server
      </li>
      <ul >
       <li>
        Allows users to communicate through video or text over the network.
       </li>
      </ul>
     </ul>
 
     <h3 id="server-functions-and-features">
      Server Functions &amp; Features
     </h3>
 
     <ul class="spaced-list">
 
      <li>Formatting:</li>
      <ul >
         <li>After partitioning a drive, it hasa to be formatted before it can be used.</li>
         <li>The format will be largly decided by what operating system the storage device is going to be mounted to.</li>
         <li>For example, windows drives should be formatted NTFS. Modern linux systems use EXT4.</li>
      </ul>
 
      <li>Connectivity:</li>
      <ul >
         <li>Servers should have the ability to connect to networks. This could be either Local Area Networks, or a Wide Area Network such as the internet.</li>
         <li>Servers should be able to support netwrk connections for virtual hosts (such as VMs or containers)</li>
      </ul>
 
      <li>Provisioning:</li>
      <ul >
         <li>When allocating storage for virtual machines, files servers, etc, you will need to know how much storage to provide to those services.</li>
         <li>"thick" provisioning: When a volume or disk is set up, all the storage space that is allocated to it is reserved immediatly</li>
         <ul >
             <li>Thick provisioning typically results in better overall performance and is much simpler to manage compared to thin provisioning, however it may result in wasted capacity.</li>
             <li>"Eager" thick provisioning: all storage blocks are whiped clean as the provision is initialized. This can offer better performance because data does not need to be deleted before it can be ovverwritted. Often used in performance oriented applications.</li>
             <li>"Lazy" thick provisioning: storage space is allocated up front, but storage blacks are not overwritten until they are needed. This means that they are faster to create, but may take longer to read and write data.</li>
         </ul>
         <li>"Thin" provisioning: instead of allocating storage up fron, it is alocated on the fly, as data is writte.</li>
         <ul >
             <li>Thin provisioning is a mych more efficient use of stoage, which can mean potential cost savings due to reduced hardware requirements.</li>
             <li>"Dynamic" thin provisioning: a maximum storage limit is set, but only the storage required is actually used.</li>
             <li>"Overcommitment" thin provisioning: More storage than what is physically available is provisioned across multiple systems (typically VMs) under the assumption that the total storage usage wil not exceed the physical storage limit.</li>
         </ul>
      </ul>
 
      <li>Swap</li>
      <ul >
       <li>Swap storage, also known as swap space or paging file, is a portion of a hard disk drive (HDD) or solid-state drive (SSD) that is used as virtual memory in an operating system (OS). It is a form of memory management where the OS can "swap out" data from the system's RAM onto the hard drive when the RAM is full, and "swap in" data back to the RAM when needed.</li>
       <li>If the system needs more memory resources and the RAM is full, inactive pages in memory are moved to the swap space. While swap space can help machines with a small amount of RAM, it should not be considered a replacement for more RAM. Swap space is much slower than RAM, because it relies on the hard drive, which is inherently slower than RAM. Because of this speed differnece, relying too much on swap space can degrade system performance. This is known as "thrashing".</li>
       <li>Understanding how much swap space your server needs is a part of capacity planning. As a rule of thumb, your swap space should be approximately 1-2 times the amount of physical RAM, depending on your system's requirements.</li>
       <li>Swap space takes up disk space. If your server is running low on disk space, one of the things to check is whether you've allocated too much space to swap.</li>
       <li>Modern Linux systems manage swap space with the "swappiness" parameter, which configures how aggressively the system uses swap space.</li>
       <li>Ideally swap storage should be on a seperate disk than the operating system.</li>
       <li>Scratch space is the same idea as swap space, but is managed by an application rather than the operating system.</li>
      </ul>
 
      <li>Storage Management</li>
      <ul >
       <li>Disk quaotas can be used to manage the amount of physical storage a user or account can occupy. There are various tools that will automatically notify users that close to or at their disk quota.</li>
       <li>Compression can be used to limit the amount physical storage a file or directoy takes up.</li>
       <li>Deduplication is a process used to remove duplicate data blocks to reduce storage usage.</li>
      </ul>
 
      <li>Monitoring</li>
      <ul >
       <li>Various tools can be used to monitor system resources such as RAM, disk, CPU utilization, as well as other metrics such as tempratures. Most of those tools will allow administrators to set thresholds, so if a resource is utilized beyond a certain point, they will recieve a notification. This notification can be a good indicator that the application needs to be scaled to a more powerful server, or across multiple servers. It could also be an indication of something like a failing hardware or software component, or even an indicator that malware is running on the system.</li>
       <li>Event logs can be tracked by monitoring tools, which can help narrow down problems while troubleshooting.</li>
       <li>Monitoring tools can also be used to keep track of the uptime of various services. Uptime is the amount of time a server or service has been running. </li>
       <li>Other things that can be monitorered include configuration files, system alerts, automated reports, disk quotas, and the page, scratch, and swap files.</li>
      </ul>
 
      <li>Data Migration / Data Transfers</li>
      <ul >
       <li>When copying data, it is important to be wary of data infiltration (malicious data being added) or exfiltration (data being "siphoned" from the transfer without permission).</li>
       <li>Robocopy:</li>
       <ul >
          <li>Robocopy (Robust File Copy) is a command-line file replication tool included with Windows. It's designed for reliable copying or mirroring of directories.</li>
          <li> Robocopy supports copying NTFS permissions, file attributes, and can resume interrupted file transfers. It also provides options for logging and can be set to only copy files that have changed.</li>
       </ul>
       <li>FTP (File Transfer Protocol):</li>
       <ul >
          <li>A standard network protocol used to transfer files from one host to another over TCP. It has a secure variant called FTPS which adds support for the Transport Layer Security (TLS).</li>
       </ul>
       <li>FastCopy:</li>
       <ul >
          <li>FastCopy is a free and open-source file copying utility for Windows. It claims to be the fastest copy/delete software on Windows. It supports different transfer modes, verification of copied files, and can handle long path names (this is a problem in windows file explaorer).</li>
       </ul>
       <li>SCP (Secure Copy Protocol):</li>
       <ul >
          <li>SCP is a means of securely transferring files between hosts using the SSH protocol.</li>
          <li>SCP encrypts both the file and any passwords, ensuring that sensitive data is kept secure during transit.</li>
       </ul>
       <li>Rsync:</li>
       <ul >
          <li>Rsync is a utility for efficiently transferring and synchronizing files across computer systems. It's commonly used in Unix-based systems.</li>
          <li>Rsync is known for its delta-transfer algorithm, which sends only the differences between the source and destination files, reducing the amount of data transferred. It can work locally or over a network and can be secured using SSH.</li>
       </ul>
      </ul>
    </ul>
 
      <h3 id="high-availability-servers">High Availability Servers</h3>
      <ul class="spaced-list">
       <li>Clustering:</li>
       <ul >
          <li>A server cluster is a group of independent servers that work together as a single system to ensure that applications and services remain available. The primary goal of clustering is to provide redundancy, which in turn provides high availability and fault tolerance.</li>
 
          <li>Benefits of clusters:</li>
          <ul >
             <li>If one node fails, another can take over, ensuring continuous service.</li>
             <li>Additional nodes can be added to the cluster to handle increased load.</li>
             <li>Load balancing can be implemented to distribute the workload evenly among nodes, preventing any single node from becoming a bottleneck.</li>
          </ul>
 
          <li>There are 3 common implementations of clustering; Failover clusters, load balancing clusters, and high perfomance clusters.</li>
 
          <li>Failover clusters:</li>
          <ul >
             <li>In this setup, if one server (or node) fails, its workload is transferred to another node in the cluster. This ensures continuous operation.</li>
             <li>Often used for databases, file servers, and virtual machines.</li>
          </ul>
 
          <li>Load Balancing Clusters:</li>
          <ul >
             <li>Incoming network traffic is distributed across multiple servers to balance the load and maximize throughput and response time.</li>
             <li>Commonly used for web servers and application servers.</li>
          </ul>
 
          <li>High Performance Clusters (HPC):</li>
          <ul >
             <li>These clusters are designed to provide high computational power by parallelizing tasks. They're not necessarily focused on high availability but rather on performance.</li>
             <li>Often used for scientific simulations, data analysis, and other compute-intensive tasks.</li>
          </ul>
 
          <li>What Systems Benefit From Clustering?</li>
          <ul >
             <li>Some applications maintain a significant amount of state information in memory (ram). This could be session data, cached information, or real-time data that the application is processing. If such an application were to crash or be interrupted, restoring its state from disk or re-computing the data could be time-consuming or even impossible in some cases. In a clustered environment, another node can take over with minimal disruption, ensuring that the in-memory state is preserved and the application continues to function.</li>
             <li>Applications that frequently write to or update a database or file system benefit from clustering. This is because clustering can provide data redundancy. In a clustered setup, data can be mirrored or replicated across nodes. If one node fails during a write operation, another node can take over, ensuring data integrity and availability. This is especially crucial for databases where data consistency and durability are paramount.</li>
             <li>Databases often hold critical data and require high availability. Clustering ensures that if one node fails, another can take over, minimizing downtime.</li>
             <li>Clustering can ensure that file services remain available, even if one server fails. This is crucial for businesses where access to files and documents is critical.</li>
             <li>For websites and applications with high traffic, clustering provides load balancing, distributing incoming requests across multiple servers. This ensures that no single server becomes a bottleneck and provides redundancy in case of server failures.</li>
             <li>Email systems like Microsoft Exchange can be set up in a clustered environment to ensure continuous email delivery and access.</li>
             <li>Virtualization platforms like VMware or Hyper-V can cluster host servers. If one host fails, the virtual machines can be quickly migrated to another host in the cluster.</li>
             <li>Clusters can be set up to provide massive computational power for tasks like scientific simulations, data analysis, and rendering.</li>
          </ul>
 
          <li>Cluster Configurations</li>
          <ul >
             <li>Active-Active</li>
             <ul >
                <li>All servers (or resources) in the setup are "active" and handle traffic or workload concurrently.</li>
                <li>Traffic or workload is distributed among the active servers. This can be done using load balancers or other distribution mechanisms.</li>
                <li>If one server fails, the remaining active servers continue to handle the traffic, ensuring there's no service interruption.</li>
                <li>Active-Active configurations can be scaled more easily. As traffic grows, more servers can be added to the active pool to handle the increased load.</li>
                <li>Active-Active setups are common in web server clusters, application server clusters, and other scenarios where load distribution is essential. It's especially useful for systems that need to handle large volumes of simultaneous requests.</li>
             </ul>
 
             <li>Active-Passive</li>
             <ul >
                <li>Some servers are "active" and handle all the traffic or workload.  The other servers in the cluster remain "passive" or in standby mode. They don't actively handle any traffic but are ready to take over if the active server fails.</li>
                <li>If the active server encounters a problem, the passive server takes over its role, ensuring continuous service. This process is known as "failover."</li>
                <li>Once the original active server is fixed or becomes operational again, it can be brought back online. Depending on the configuration, it might return as the active server, or it might assume the passive role until another failover event occurs.</li>
                <li>Active-Passive setups are common in database systems, file servers, and other scenarios where data consistency is crucial. The passive server often mirrors the data of the active server to ensure a seamless transition during failover.</li>
             </ul>
 
             <li>Differences:</li>
             <ul >
                <li>In Active-Active, all resources are utilized concurrently, offering potentially higher performance and throughput. In Active-Passive, the passive resource remains on standby, so its capacity isn't utilized until a failover event.</li>
                <li>Active-Active configurations can be more complex due to the need to synchronize data and state across all active nodes. Active-Passive setups, while simpler, require mechanisms to ensure a smooth failover process.</li>
                <li>Active-Active configurations might have higher operational costs since all nodes are active and consuming resources. However, they can handle more traffic without additional scaling.</li>
             </ul>
 
             
             <li>Server "Heartbeats"</li>
             <ul >
                <li>A heartbeat is a periodic signal sent between servers (or nodes) in a cluster to indicate that they are operational and "alive." It's a mechanism to detect the health and status of nodes within the cluster.</li>
                <li>Nodes in a cluster send heartbeat signals to each other at regular intervals. This is usually done over a dedicated network connection to ensure reliability.</li>
                <li>If a node fails to receive a heartbeat from a peer within a specified time frame, it assumes that the peer is unavailable or has failed.</li>
                <li> Once a node is determined to be unavailable based on missed heartbeats, failover procedures can be initiated. In an Active-Passive configuration, for example, the passive node might take over the role of the active node if it detects that the active node is down.</li>
                <li>The heartbeat mechanism helps prevent a "split-brain" scenario. Split-brain occurs when network communication between nodes breaks down, but both nodes are still operational. Without a heartbeat or other quorum mechanism, both nodes might assume they are the "active" node and start accepting work, leading to data inconsistency or conflicts.</li>
                <li>Combining heartbeats with other metrics, such as CPU usage, memory usage, or disk activity, can provide a more comprehensive view of node health.</li>
                <li>External network monitoring tools can be used to check the health and status of nodes in a cluster. These tools can send alerts or even trigger failover actions if a node becomes unreachable or exhibits other signs of failure.</li>
             </ul>
             
          </ul>
       </ul>
 
       <li>Clustering Alternatives:</li>
       <ul >
          <li>Replication:</li>
          <ul >
             <li>Data is duplicated across multiple servers. If one server fails, another with the replicated data can take over.</li>
             <li>Common in database systems where you might have a primary database and one or more replicas.</li>
          </ul>
 
          <li>Backup and Restore:</li>
          <ul >
             <li>Regular backups are taken and stored securely. In the event of a failure, the system can be restored from the latest backup.</li>
             <li>This method might not provide immediate failover like clustering but is essential for data recovery.</li>
          </ul>
 
          <li>Virtualization and Live Migration:</li>
          <ul >
             <li>Virtual machines (VMs) can be migrated from one physical host to another without downtime. If a host is about to fail or needs maintenance, VMs can be moved to another host.</li>
             <li>Tools like VMware vMotion or Hyper-V Live Migration support this.</li>
          </ul>
 
          <li>Geographic Redundancy:</li>
          <ul >
             <li>Deploying infrastructure in multiple geographic locations. If one entire data center fails due to a catastrophic event, another data center in a different location can take over.</li>
             <li>This is commonly implemented in cloud environments.</li>
          </ul>
 
          <li>DNS Failover:</li>
          <ul >
             <li>DNS is configured to point to multiple IP addresses. If one server is unreachable, DNS can redirect traffic to a secondary server.</li>
             <li>This method is often used in conjunction with other HA strategies.</li>
          </ul>
 
          <li>Content Delivery Networks (CDN):</li>
          <ul >
             <li>CDNs distribute content across a network of servers. If one server fails, the CDN can serve content from another server.</li>
             <li>Commonly used for web content, especially for global audiences.</li>
          </ul>
       </ul>
    </ul>
 
 
       <h3 id="high-availability-networking">High Availability Networking</h3>
       <ul class="spaced-list">
          <li>Load Balancing</li>
          <ul class="spaced-list">
             <li>Load balancing is a technique used to distribute incoming network traffic across multiple servers or resources to ensure optimal resource utilization, maximize throughput, minimize response time, and prevent overload on any single server.</li>
             <li>Load balancing provides fault tolerance. If one server fails, the load balancer redirects traffic to the remaining operational servers.</li>
             <li>As traffic increases, more servers can be added to the load balancer.</li>
             <li>Load balancing ensures that no single server is overwhelmed with too much traffic, leading to optimal resource utilization.</li>
 
             <li>Round Robin:</li>
             <ul >
                <li>This method maintains a list of servers associated with the load balancer. Every time a request comes in, the load balancer forwards the request to the next server in the list. Once it reaches the end of the list, it starts over from the beginning.</li>
                <li>For example, with three servers A, B, and C, the first request goes to A, the second to B, the third to C, the fourth back to A, and so on.</li>
                <li>Doesn't account for server load or health. If one server is slower or overloaded, it can become a bottleneck.</li>
             </ul>
 
             <li>Least Connections:</li>
             <ul >
                <li>The load balancer keeps track of the number of active connections to each server. Incoming requests are directed to the server with the fewest active connections.</li>
                <li>Useful when servers have varying levels of processing power, and some can handle more connections than others.</li>
                <li>Doesn't account for the duration or complexity of tasks on each server.</li>
             </ul>
             
             <li>Least Response Time:</li>
             <ul >
                <li>The load balancer periodically checks the response times of servers (usually by sending a simple request). Incoming traffic is directed to the server with the lowest response time.</li>
                <li>Frequent health checks can add overhead.</li>
             </ul>
             
             <li>IP Hash:</li>
             <ul >
                <li>A deterministic hash function processes the client's IP address to determine which server should handle the request. This ensures that a specific client will always be directed to the same server. This ensures session persistence for applications that store session data on the server.</li>
                <li>If a server goes down, the hash might direct traffic to it until the load balancer is updated.</li>
             </ul>
             
             <li>Weighted Load Balancing:</li>
             <ul >
                <li>Each server is assigned a weight, typically based on its capacity or performance. The load balancer uses these weights to distribute incoming requests proportionally.</li>
                <li>Requires manual configuration and adjustment of weights.</li>
             </ul>
             
             <li>Layer 7 Load Balancing:</li>
             <ul >
                <li>Distributes requests based on content type, URL, or other HTTP header information. This allows for more intelligent distribution, such as sending all requests for images to one server and all requests for database queries to another.</li>
             </ul>
             
             <li>Sticky Sessions (Session Persistence):</li>
             <ul >
                <li>The load balancer uses a mechanism (like cookies or source IP hashing) to ensure that a client is consistently directed to the same server as long as its session is active.</li>
                <li>Can lead to uneven distribution of traffic, especially if some sessions are longer or more resource-intensive than others.</li>
             </ul>
             
             <li>Global Server Load Balancing (GSLB):</li>
             <ul >
                <li>Uses DNS resolution to direct clients to the nearest or best-performing data center. Health checks and performance metrics are used to determine the optimal data center for each request.</li>
                <li>Provides geographic redundancy and directs users to the nearest data center for reduced latency.</li>
                <li>Relies on DNS propagation, which might not be instantaneous.</li>
             </ul>
 
 
             <li>Hardware vs. Software Load Balancers:</li>
             <ul >
                <li>Hardware Load Balancers are dedicated appliances optimized for processing network traffic. They are typically faster and more reliable but can be more expensive.</li>
                <li>Software Load Balancers run on general-purpose operating systems and hardware. They offer more flexibility and can be more cost-effective, especially for smaller setups or cloud environments. Examples include Nginx, HAProxy, and the AWS Elastic Load Balancer.</li>
             </ul>
 
             <li>Application vs. Network Load Balancers:</li>
             <ul >
                <li>Application Load Balancers (Layer 7) operate at the application layer and make routing decisions based on content type, URL, or other HTTP header information.</li>
                <li>Network Load Balancers (Layer 4) operate at the transport layer and make routing decisions based on IP address and port. They are typically faster and less resource-intensive than application load balancers.</li>
             </ul>
 
             <li>Load Balancing in Software Defined Networking</li>
             <ul >
                <li>SDN (Software Defined Networking) is an approach to networking that uses software-based controllers or application programming interfaces (APIs) to direct traffic on the network and communicate with the underlying hardware infrastructure.</li>
                <li>A load balancing adaptive algorithm is designed to analyze various factors and adjust itself to make optimal load balancing decisions. These factors might include server load, network congestion, application status, etc.</li>
                <li>These algorithms take data from various layers of the OSI model to make their loag balancing decisions:</li>
                <ol>
                   <li>Presentation Layer: Deals with translation, compression, and encryption of data.</li>
                   <li>Transport Layer: Ensures that data is delivered error-free, in the correct sequence, and without losses or duplications.</li>
                   <li>Data Link Layer: Provides a link between two directly connected nodes and handles error detection and correction.</li>
                   <li>Network Layer: Determines the best path to route the data from the source to the destination.</li>
                </ol>
                <li>From the Presentation and Transport Layers: The load balancer learns about the type of data, its format, error-handling requirements, and the sequence. This can help in understanding the application requirements.</li>
                <li>From the Data Link & Network Layers: The load balancer gains insights into the network's structure, link status, routing paths, and overall network health.</li>
                <li>By utilizing information from these various layers, the adaptive algorithm can make more informed and dynamic decisions in real-time. This means better distribution of load across servers, reduced latency, and the ability to adapt to failures and changes in the network.</li>
             </ul>
          </ul>
 
          <li>Network Interfaces</li>
          <ul class="spaced-list">
             <li>NIC (Network Interface Card) Teaming</li>
             <ul >
                <li>NIC teaming is managed by LACP (Link Aggregation Control Protocol)</li>
                <ul >
                   <li>LACP is a protocol used to bundle several physical network links into a single logical link, known as a Link Aggregation Group (LAG). It's part of the IEEE 802.1AX standard.</li>
                   <li>When LACP is enabled on a port, it starts sending LACP Data Units (LACPDUs) to discover LACP-capable peers.</li>
                   <li>LACP negotiates with the peer devices to determine which links can be bundled together, based on parameters like speed, duplex setting, etc.</li>
                   <li>The selected links are bundled into a single logical link (LAG), and traffic is distributed across them.</li>
                   <li>LACP continually monitors the links, and if a change is detected (like a link failure), it dynamically reconfigures the LAG.</li>
                   <li>LACP devices have 2 operating modes:</li>
                   <ol>
                      <li>Active Mode: Actively sends LACPDUs, initiating negotiations with peers.</li>
                      <li>Passive Mode: Waits for LACPDUs from peers and responds but doesn't initiate negotiations.</li>
                   </ol>
                </ul>
                <li>NIC teaming is used to group multiple NICs together in a similar way to a raid array.</li>
                <li>NIC teaming can be used to aggragate the bandwidth of multiple ncs together, and if one nic fails, the other can maintain a connection to the netwrok.</li>
                <li>NIC teaming is also referred to as link aggregation or link bonding.</li>
             </ul>
          </ul>
 
          <li>Virtual Networking</li>
          <ul >
             <li>Virtual networking allows multiple VMs to communicate with each other and with the physical network, just as if they were physical devices.</li>
             <li>Bridged connections:</li>
             <ul >
                <li>A virtual bridge connects a virtual network interface card (vNIC) inside a VM to a physical network interface card (pNIC) on the host machine.</li>
                <li>The VM appears as a separate physical device on the network, with its own MAC and IP address. It communicates directly with the physical network, bypassing the host's network stack.</li>
                <li>Bridged connections are ideal when VMs need to be part of the same physical network as the host, such as in web servers or database servers.</li>
             </ul>
             <li>NAT (Netwrok Address Translation)</li>
             <ul >
                <li>NAT is a method of remapping one IP address space into another by modifying network address information in the IP header of packets while they are in transit. In virtual networking, NAT allows VMs to share the host's IP address.</li>
                <li>VMs are assigned private IP addresses. When a VM sends a packet to the external network, the source address is translated to the host's public IP address.</li>
                <li>NAT keeps a translation table to map the VM's private IP and port to the host's public IP and a unique port. This ensures that return traffic is correctly directed to the originating VM.</li>
                <li>VMs are isolated from the external network, as they do not have direct access. They communicate with the outside world through the NAT service on the host. This provides a layer of isolation between VMs and the external network, acting as a basic firewall.</li>
                <li>Most virtualization platforms like VMware, VirtualBox, and Hyper-V provide options to configure NAT for VMs.</li>
                <li>Types of NAT setups:</li>
                <ul >
                   <li>Static NAT: Predefined mapping between private and public addresses.</li>
                   <li>Dynamic NAT: Dynamic mapping between private and public addresses, usually using a pool of public IPs.</li>
                   <li>Port Address Translation (PAT): Multiple private IPs are mapped to a single public IP using different port numbers.</li>
                </ul>
             </ul>
 
             <li>Host-Only Networking</li>
             <ul >
                <li>Host-Only Networking allows communication between the virtual machines (VMs) and the host system, but the VMs are isolated from the external network.</li>
                <li>How it works:</li>
                <ul >
                   <li>Virtual Switch: A virtual switch is created that connects the VMs and the host.</li>
                   <li>Isolation: VMs can communicate with each other and the host but not with the external network.</li>
                   <li>IP Configuration: VMs are usually assigned IP addresses in a private range, either statically or via a virtual DHCP server.</li>
                </ul>
                <li>Host Only Networking provides isolation from the external network, enhancing security. It is often simpler to configure than other networking modes.</li>
                <li>Ideal for creating isolated development or testing environments where VMs need to communicate with the host but not the external network.</li>
                <li>Useful for simulating network scenarios without affecting the physical network.</li>
             </ul>
 
             <li>Internal Networking</li>
             <ul >
                <li>Internal Networking is similar to Host-Only Networking but with even more isolation. VMs can communicate with each other but not with the host or the external network.</li>
                <li>How it works:</li>
                <ul >
                   <li>Virtual Switch: A virtual switch is created that connects the VMs.</li>
                   <li>Complete Isolation: VMs can communicate only with each other, not with the host or the external network.</li>
                   <li>IP Configuration: IP addresses can be assigned statically or via a virtual DHCP server running inside one of the VMs.</li>
                </ul>
                <li>Internal Networking provides a completely isolated environment, enhancing security. This allows for safe experimentation without any risk to the host or external network.</li>
                <li>Ideal for testing potentially harmful software or network attacks in a completely isolated environment.</li>
                <li>Useful for modeling complex network scenarios without any risk to the existing infrastructure.</li>
             </ul>
          </ul>
       </ul>
 
       <h3 id="virtualization">Virtualization</h3>
       <ul class="spaced-list">
          <li>Virtualization is the technology that allows the creation of virtual instances of physical resources, such as servers, storage, and network devices. It enables multiple virtual machines (VMs) to run on a single physical machine, sharing its resources.</li>
          <li>Type 1 hypervisors are generally used in virtualized network settings. A Type 1 hypervisor, also known as a "bare-metal" hypervisor, runs directly on the host's hardware to control the hardware and manage guest operating systems.</li>
 
          <ul >
             <li>Generally offers better performance as it has direct access to physical hardware (compared to type 2 hypervisors).</li>
             <li>More secure as there's no underlying OS to be attacked.</li>
             <li>Many Type 1 hypervisors support clustering, allowing multiple hosts to work together for redundancy and load balancing.</li>
             <li>Features like VMware HA provide automated failover for VMs, restarting them on other hosts if a failure occurs.</li>
             <li>Allows VMs to be moved between hosts without downtime, facilitating maintenance and load balancing.</li>
          </ul>
 
          <li>Many virtualization platforms support clustering.</li>
          <li>Virtualization allows for efficient use of physical resources, enabling the creation of redundant VMs without the need for as many physical machines.</li>
          <li>Virtualization platforms often include tools for monitoring VM health and automatically moving VMs to healthy hosts if a failure is detected.</li>
          <li>Virtualization enables dynamic load balancing, distributing workloads across multiple VMs to ensure optimal performance.</li>
          <li>Virtualized environments often allow for rapid provisioning of new VMs, enabling quick recovery from failures.</li>
          <li>Virtualization simplifies disaster recovery by enabling easy replication and migration of VMs between sites.</li>
       </ul>
 
       <ul class="spaced-list">
          <li>Resource Allcation:</li>
          <ul class="spaced-list">
             <li>Resource allocation in virtualization is a critical aspect, especially when considering high availability (HA). It involves the distribution and management of physical resources (such as CPU, memory, storage, and network) among virtual machines (VMs) to ensure optimal performance, scalability, and resilience. </li>
 
             <li>CPU/Memory</li>
             <ul >
                <li>Shares: CPU cores/RAM is shared between VMs as needed. If a VM has more shares compared to others, it gets a larger portion of the CPU/memory resources during contention.</li>
                <li>Reservations: This is the guaranteed minimum amount of CPU/memory resources allocated to a VM. It ensures that the VM will always have access to the specified amount of resources.</li>
                <li>Limits: This sets the maximum amount of resources that a VM can consume. Even if more resources are available, the VM won't be able to use beyond this limit.</li>
             </ul>
             <li>Storage:</li>
             <ul>
                <li>Virtualized servers use virtualized storage, which means that physical storage devices are abstracted and presented as logical units. This allows multiple virtual servers to share the same physical storage resources.</li>
                <li>Physical storage devices are grouped into storage pools, which can be allocated to different virtual machines (VMs) as needed.</li>
                <li>Virtualized storage often uses specific file systems and formats like VMFS (Virtual Machine File System) to manage data efficiently.</li>
                <li>Direct Attached Storage (DAS): Storage devices are directly attached to the host machine. This offers high performance but lacks flexibility.</li>
                <li>Network Attached Storage (NAS): a file-level data storage device that is connected to a computer network, providing data access to a heterogeneous group of clients.</li>
                <ul >
                   <li>NAS operates at the file level, meaning it handles data as files and directories.</li>
                   <li>Commonly uses protocols like NFS (Network File System) or SMB/CIFS (Server Message Block/Common Internet File System).</li>
                   <li>Suitable for moderate performance needs, such as file sharing, backups, and multimedia streaming.</li>
                </ul>
                <li>Storage Area Network (SAN): a network that provides access to consolidated, block-level data storage, primarily used to make storage devices accessible to servers in a way that the devices appear as locally attached.</li>
                <ul >
                   <li>SAN operates at the block level, handling raw data blocks, which allows for more efficient handling of large data sets and applications like databases.</li>
                   <li>Utilizes protocols like iSCSI (Internet Small Computer Systems Interface) or Fibre Channel.</li>
                   <li>Generally more complex to set up and requires specialized knowledge, but is suitable for large enterprises because it is highly scalable, allowing for growth and expansion as needed.</li>
                   <li>Offers high performance and is ideal for applications that require fast data retrieval and processing, such as large databases and virtualization.</li>
                </ul>
             </ul>
          </ul>
 
          <li>VM mangement</li>
          <ul >
             <li>VMware vCenter Server is a centralized management platform for VMware vSphere environments.</li>
             <ul >
                <li>Manages multiple ESXi hosts and VMs from a single console.</li>
                <li>Offers automation and orchestration capabilities.</li>
                <li>Can manage thousands of VMs.</li>
                <li>Works with other VMware products for complete virtualization management.</li>
             </ul>
             <li>Hyper-V Manager is a tool used to create, manage, and configure virtual machines in Microsoft's Hyper-V virtualization platform.</li>
             <ul >
                <li>Native to Windows Server and Windows 10 and 11.</li>
                <li>Suitable for small to large-scale deployments.</li>
             </ul>
             <li>Citrix Hypervisor is an open-source virtualization platform based on the Xen Project.</li>
             <ul >
                <li>Can be integrated with other Citrix products for a complete virtualization solution.</li>
             </ul>
             <li>Red Hat Virtualization is an enterprise virtualization solution provided by Red Hat.</li>
             <ul >
                <li>Built on Red Hat Enterprise Linux.</li>
                <li>Provides APIs for integration and automation.</li>
                <li>Includes security features aligned with Red Hat's security standards.</li>
             </ul>
             <li>Oracle VM VirtualBox is a free and open-source hosted hypervisor for x86 virtualization.</li>
             <ul >
                <li>Runs on Windows, Linux, macOS, and other platforms.</li>
                <li>Known for its ease of use and community support.</li>
             </ul>
          </ul>
 
          <li>Cloud Models</li>
          <ul >
             <li>Public Cloud</li>
             <ul >
                <li>Public cloud refers to a computing service model where a service provider makes resources, such as virtual machines (VMs), applications, or storage, available to the general public over the internet. Public cloud services may be free or sold on-demand.</li>
                <li>Easily scalable to accommodate varying demands.</li>
                <li>In most cases, resources are shared among multiple users.</li>
                <li>Environment is managed and maintained by the cloud provider.</li>
                <li>The most common coud providers are Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP).</li>
             </ul>
 
             <li>Private Cloud</li>
             <ul >
                <li>Private cloud is a cloud computing model that offers a proprietary environment dedicated to a single business entity. Unlike the public cloud, it is not shared with other organizations.</li>
                <li>Can be tailored to meet specific business needs.</li>
                <li>Greater control over the environment, including security and compliance.</li>
                <li>Can be hosted on-premises or by a third-party provider.</li>
                <li><a href="https://docs.vmware.com/en/VMware-Cloud-Director/index.html" class="link" target="_blank">VMware's vCloud</a></li>
                <ul >
                   <li>VMware's vCloud is a cloud computing initiative that provides a suite of cloud computing services, including infrastructure as a service (IaaS), delivered by VMware's vCloud partners.</li>
                   <li>Can be integrated with public clouds to create a hybrid cloud environment.</li>
                </ul>
 
                <li><a href="https://docs.openstack.org/2023.1/" class="link" target="_blank">OpenStack</a></li>
                <ul >
                   <li>OpenStack is an open-source cloud computing platform that enables organizations to control large pools of compute, storage, and networking resources throughout a data center.</li>
                   <li>Supports various hypervisors, including KVM, VMware, and Xen.</li>
                   <li>Can be tailored to meet specific organizational needs.</li>
                </ul>
             </ul>
 
             <li>Hybrid Cloud</li>
             <ul >
                <li>Hybrid cloud is a computing environment that combines a mix of on-premises, private cloud, and third-party public cloud services. It allows data and applications to be shared between them.</li>
                <li>Allows for greater flexibility in moving workloads between cloud solutions.</li>
                <li>Can optimize costs, performance, and efficiency.</li>
             </ul>
          </ul>
          
       </ul>
      
    </div>

   </section>